{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84tKDlXJHsbV"
      },
      "source": [
        "# Lab 3 - Optymalizacja hiperparametrów sieci neuronowej"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAau1adEOtER"
      },
      "source": [
        "Optymalizacja hiperparametrów to najważniejszy etap podczas trenowania sieci neuronowej. Hiperparametry, takie jak współczynnik uczenia (learning rate), liczba neuronów w warstwach, wielkość grupy (batch size) czy współczynnik porzucania (dropout), nie są bezpośrednio optymalizowane podczas treningu modelu, ale mają znaczący wpływ na jego wydajność. Dobrze dobrane hiperparametry mogą znacząco poprawić dokładność, szybkość uczenia i zdolność generalizacji modelu. Proces ich ręcznego doboru bywa jednak czasochłonny i opiera się często na intuicji lub metodzie prób i błędów.\n",
        "\n",
        "Z uwagi na wymienione okoliczności, powszechnie wykorzystuje się automatyczne narzędzia do optymalizacji hiperparametrów, takie jak **Optuna**. Jest to biblioteka otwartoźródłowa, przeznaczona do optymalizacji funkcji kosztu, stworzona specjalnie z myślą o prostocie i wydajności. Optuna wykorzystuje złożone techniki eksploracji przestrzeni parametrów, m.in. sekwencyjną optymalizację Bayesowską, by znaleźć optymalne ustawienia hiperparametrów przy minimalnej liczbie prób. Dzięki temu potrafi szybciej znaleźć lepsze rozwiązania niż metody takie jak deterministyczne lub stochastyczne przeszukiwanie siatki.\n",
        "\n",
        "Biblioteka Optuna dobrze integruje się z popularnymi bibliotekami do uczenia maszynowego, takimi jak TensorFlow, PyTorch, czy scikit-learn. Umożliwia definiowanie funkcji celu jako zwykłych funkcji języka Python, w których można dowolnie próbować różnych architektur modelu, parametrów optymalizatora, czy strategii regularizacji. Co więcej, Optuna oferuje przyjazne narzędzia do wizualizacji postępów i wyników optymalizacji, co ułatwia analizę procesu i interpretację wyników."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e3Pg8_IIxUr"
      },
      "source": [
        "## Optymalizacja nieliniowej funkcji jednej zmiennej"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lss6370zI2nI"
      },
      "source": [
        "$f(x) = (x - 2)^2 + 1$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XimT15wJL_Y"
      },
      "source": [
        "Cel: minimalizacja parametru $x$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Vd6paZBI_Kb"
      },
      "outputs": [],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IUu5vJv1BL3Y"
      },
      "outputs": [],
      "source": [
        "from typing import Any\n",
        "\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Y5Wu5X1yJX54"
      },
      "outputs": [],
      "source": [
        "def f(x: float) -> float:\n",
        "  return (x - 2)**2 + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ssmbjXcLI65v"
      },
      "outputs": [],
      "source": [
        "def objective(trial: Any) -> float:\n",
        "    x = trial.suggest_float(\"x\", -10, 10)\n",
        "    return f(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUrTTUZlJggM"
      },
      "source": [
        "Uruchomienie optymalizacji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_S_j0hcJWfB"
      },
      "outputs": [],
      "source": [
        "study = optuna.create_study(direction=\"minimize\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClA9A_vsJid2"
      },
      "outputs": [],
      "source": [
        "study.optimize(objective, n_trials=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyEdJmbkJny1"
      },
      "source": [
        "Wyniki"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgejDhfKJlGZ"
      },
      "outputs": [],
      "source": [
        "print(f\" Dla x = {study.best_params['x']}, minimalna warość funkcji wynosi: {study.best_value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVBEPzryKAhe"
      },
      "source": [
        "## Optymalizacja funkcji wielu zmiennych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoDX9gawKMuy"
      },
      "source": [
        "$f(x, y) = (x - 3)^2 + (y + 1)^2 + 5$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bwoj9X7dJwS3"
      },
      "outputs": [],
      "source": [
        "def f(x: float, y: float) -> float:\n",
        "  return (x - 3)**2 + (y + 1)**2 + 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FrGa__rwKKYK"
      },
      "outputs": [],
      "source": [
        "def objective(trial: Any) -> float:\n",
        "  x = trial.suggest_float(\"x\", -10, 10)\n",
        "  y = trial.suggest_float(\"y\", -10, 10)\n",
        "\n",
        "  return f(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcZRK8bcKdmn"
      },
      "source": [
        "Uruchomienie optymalizacji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RE8iwxA1Kbqs"
      },
      "outputs": [],
      "source": [
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iqY5tY2KhE4"
      },
      "outputs": [],
      "source": [
        "print(f\" Dla x = {study.best_params['x']}, y = {study.best_params['y']}, minimalna warość funkcji wynosi: {study.best_value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNzhHYXiK4Z9"
      },
      "source": [
        "## Optymalizacja hiperparametrów sieci neuronowej"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-TBqLPRCKlQ9"
      },
      "outputs": [],
      "source": [
        "from typing import Any\n",
        "\n",
        "import numpy as np\n",
        "import optuna\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWy7ORsVLOxy"
      },
      "source": [
        "Wczytanie danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ehf4DgKrLLjX"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uk82wlBMLdPl"
      },
      "source": [
        "Funkcja celu: maksymalizacja dokładności zbalansowanej"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5SxQrfNTLRyl"
      },
      "outputs": [],
      "source": [
        "def objective(trial: Any) -> float:\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(28, 28)))\n",
        "\n",
        "    n_units = trial.suggest_int(\"n_units\", 32, 128)\n",
        "    model.add(Dense(n_units, activation=\"relu\"))\n",
        "\n",
        "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
        "    model.add(Dropout(dropout_rate))\n",
        "\n",
        "    model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss=\"categorical_crossentropy\",\n",
        "                  metrics=[\"categorical_accuracy\"])\n",
        "\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=trial.suggest_categorical(\"batch_size\", [32, 64, 128]),\n",
        "              epochs=5,\n",
        "              verbose=2,\n",
        "    )\n",
        "\n",
        "    loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLYACfTtM6Bi"
      },
      "source": [
        "Optymalizacja hiperparametrów:\n",
        "- n_units: liczba neuronów w warstwie ukrytej,\n",
        "- dropout_rate: prawdopodobieństwo porzucenia neuronu,\n",
        "- lr: współczynnik uczenia,\n",
        "- batch size: rozmiar grupy obiektów."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KLMSw8UNAFp"
      },
      "outputs": [],
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp9SSRqfNQ93"
      },
      "source": [
        "Najlepsze hiperparametry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iP9NTlQaNSi-"
      },
      "outputs": [],
      "source": [
        "for key, val in study.best_params.items():\n",
        "    print(f\"{key}: {val}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4RgVNQANVHe"
      },
      "outputs": [],
      "source": [
        "print(f\"Najlepszy wynik walidacji: {study.best_value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FNYtWDjQ8wD"
      },
      "source": [
        "## Zadania"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkiKR85RREVf"
      },
      "source": [
        "1. Zaimplementować funkcję nieliniową $f(x) = (x = 5)^2 + 3$ i wykorzystać bibliotekę Optuna do znalezienia wartości x minimalizującej tę funkcję.\n",
        "2. Zdefiniować funkcję dwóch zmiennych $f(x, y) = sin(x) + cos(y) + 0.1(x^2 + y^2)$. Użyć Optuny, aby znaleźć wartości x i y, które minimalizują tę funkcję.\n",
        "3. Zaprojektować funkcję celu opartą na kombinacji trzech zmiennych: $f(x, y, x) = a^2 + b^2 + c^2 - ab + sin(c)$, a następnie znaleźć minimalną wartość tej funkcji za pomocą Optuny.\n",
        "4. Zoptymalizować parametry funkcji $f(x, y) = e ^ {x ^ {2} + y ^ {2}} - 2x + 3y$, gdzie $x, y \\in [-2, 2]$. Porównać wynik z metodą deterministycznego przeszukiwania siatki.\n",
        "5. Zbudować splotową sieć neuronową w TensorFlow do klasyfikacji obrazów ze zbioru CIFAR-10. Ograniczyć podzbiór treningowy do 15000 przykładów, a liczbę epok do maks. 15. Należy także zadbać o zastosowanie podstawowych technik poprawiających uogólnianie (Dropout, BatchNormalization). Ocenić dokładność na podzbiorze walidacyjnym.\n",
        "6. Wykorzystać bibliotekę Optuna do optymalizacji struktury sieci z zadania 5. W tym celu należy dobrać:\n",
        "- liczbę filtrów w każdej warstwie splotowej (zwykle 16, 32, 64, ...),\n",
        "- liczbę warstw splotowych (zwykle 1-9),\n",
        "- rozmiar jądra splotu (zwykle 3x3, 5x5, ...),\n",
        "- funkcje aktywacji.\n",
        "7. Rozszerzyć eksperyment z zadania 6 o optymalizację strategii treningu. Wykorzystać Optunę do dobrania:\n",
        "- learning rate (1e-5 do 1e-2, z log=True),\n",
        "- optymalizatora (adam, sgd, rmsprop),\n",
        "- współczynnika Dropout (0.1–0.5),\n",
        "- wielkości grupy (16, 32, 64, ...).\n",
        "8. Użyć zbioru danych Adult (dostępny np. w sklearn.datasets.fetch_openml) do klasyfikacji (czy osoba zarabia >50k). Zbudować potok, który:\n",
        "- automatycznie koduje dane kategorialne,\n",
        "- skaluje dane numeryczne,\n",
        "- dobiera liczbę warstw ukrytych i neuronów dla każdej warstwy (Optuna),\n",
        "- testuje różne funkcje aktywacji (relu, selu, elu, tanh).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NutAY9WfObFp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
